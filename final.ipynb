{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_kddcup99\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "import wkpp as wkpp\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real data input\n",
    "dataset = fetch_kddcup99()  # Fetch kddcup99\n",
    "data = dataset.data  # Load data\n",
    "data = np.delete(data, [0, 1, 2, 3], 1)  # Preprocess\n",
    "data = data.astype(float)  # Preprocess\n",
    "data = StandardScaler().fit_transform(data)  # Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.size(data, 0)  # Number of points in the dataset\n",
    "d = np.size(data, 1)  # Number of dimension/features in the dataset.\n",
    "k = 17  # Number of clusters (say k = 17)\n",
    "Sample_size = 100  # Desired coreset size (say m = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D2(data, k):\n",
    "    # Initialize the centers with the first randomly selected point\n",
    "    centers = [data[random.randint(0, len(data) - 1)]]\n",
    "\n",
    "    # Sample subsequent centers\n",
    "    for _ in range(k - 1):\n",
    "        # Calculate squared distances from each point to the nearest center\n",
    "        distances = np.array([min(cdist([x], centers, 'sqeuclidean')[0]) for x in data])\n",
    "\n",
    "        # Calculate probabilities proportional to the squared distances\n",
    "        probs = distances / distances.sum()\n",
    "\n",
    "        # Choose the next center based on the calculated probabilities\n",
    "        next_center = random.choices(data, probs)[0]\n",
    "\n",
    "        # Add the next center to the list of centers\n",
    "        centers.append(next_center)\n",
    "\n",
    "    return np.array(centers)\n",
    "\n",
    "\n",
    "\n",
    "centers = D2(data, k)  # Call D2-Sampling (D2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sampling(data, k, centers, Sample_size):  # Coreset construction function.\n",
    "    # Compute squared distances from each point to each center\n",
    "    distances = cdist(data, centers, 'sqeuclidean')\n",
    "\n",
    "    # Assign weights based on the closest center\n",
    "    weights = np.min(distances, axis=1)\n",
    "\n",
    "    # Normalize weights to define a distribution\n",
    "    weights /= np.sum(weights)\n",
    "\n",
    "    # Sample points based on the computed weights\n",
    "    indices = np.random.choice(np.arange(len(data)), size=Sample_size, replace=False, p=weights)\n",
    "    coreset = data[indices]\n",
    "\n",
    "    return coreset, weights  # Return coreset points and its weights.\n",
    "\n",
    "\n",
    "coreset, weight = Sampling(data, k, centers, Sample_size)  # Call coreset construction algorithm (Sampling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---Running KMean Clustering---#\n",
    "fkmeans = KMeans(n_clusters=k, init='k-means++')\n",
    "fkmeans.fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Practical Coresets performance----# \t\n",
    "Coreset_centers, _ = wkpp.kmeans_plusplus_w(coreset, k, w=weight, n_local_trials=100)\t\t\t\t\t\t# Run weighted kMeans++ on coreset points\n",
    "wt_kmeansclus = KMeans(n_clusters=k, init=Coreset_centers, max_iter=10).fit(coreset,sample_weight = weight)\t# Run weighted KMeans on the coreset, using the inital centers from the above line.\n",
    "Coreset_centers = wt_kmeansclus.cluster_centers_\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Compute cluster centers\n",
    "coreset_cost = np.sum(np.min(cdist(data,Coreset_centers)**2,axis=1))\t\t\t\t\t\t\t\t\t\t# Compute clustering cost from the above centers\n",
    "reative_error_practicalCoreset = abs(coreset_cost - fkmeans.inertia_)/fkmeans.inertia_\t\t\t\t\t\t# Computing relative error from practical coreset, here fkmeans.inertia_ is the optimal cost on the complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Uniform Sampling based Coreset-----#\n",
    "tmp = np.random.choice(range(n), size=Sample_size, replace=False)\n",
    "sample = data[tmp][:]\n",
    "sweight = n * np.ones(Sample_size) / Sample_size\n",
    "sweight = sweight / np.sum(sweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Uniform Sampling based Coreset performance-----#\n",
    "wt_kmeansclus = KMeans(n_clusters=k, init='k-means++', max_iter=10).fit(sample, sample_weight=sweight)\n",
    "Uniform_centers = wt_kmeansclus.cluster_centers_\n",
    "uniform_cost = np.sum(np.min(cdist(data, Uniform_centers) ** 2, axis=1))\n",
    "relative_error_uniformCoreset = abs(uniform_cost - fkmeans.inertia_) / fkmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Relative error from Practical Coreset is\", relative_error_practicalCoreset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error from Uniformly random Coreset is 1.1944140125106901\n"
     ]
    }
   ],
   "source": [
    "print(\"Relative error from Uniformly random Coreset is\", relative_error_uniformCoreset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
